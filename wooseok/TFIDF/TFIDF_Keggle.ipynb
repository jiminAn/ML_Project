{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da376f5",
   "metadata": {},
   "source": [
    "# 1. Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53fc8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for loading and preprocessing the data\n",
    "import torch\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "\n",
    "# for training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "\n",
    "# for evaluating classification model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51605f0f",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7573a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDFInput/train_added.csv\n",
      "TFIDFInput/train.csv\n",
      "TFIDFInput/sample_submission.csv\n",
      "TFIDFInput/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('TFIDFInput'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "pd.set_option('display.width',1000000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "score_df = pd.DataFrame(columns={'Model Description','Score'})\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "test = pd.read_csv(\"TFIDFInput/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3f2ea",
   "metadata": {},
   "source": [
    "## 2.1 Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64e423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263, 4)\n",
      "id          False\n",
      "keyword      True\n",
      "location     True\n",
      "text        False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbf8ee",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbf055",
   "metadata": {},
   "source": [
    "## 3.3 Processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c64a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepocessing with regrex\n",
    "\n",
    "def remove_URL(text): # remove url pattern in text\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "def remove_html(text): # remove html pattern in text\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return html.sub(r'', text)\n",
    "    #return re.sub(html, '', text)\n",
    "\n",
    "def remove_punct(text): # remove punctuation in text: (;, ', \", :, ., , etc..)\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab4e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"i'll\", \"i will\", text)\n",
    "    text = re.sub(r\"she'll\", \"she will\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"here's\", \"here is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74448044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def massage_text(text):  # 이건 안하는 게 성능 향상에 좋다.\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    ## remove anything other then characters and put everything in lowercase\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lem = WordNetLemmatizer()\n",
    "    tweet = [lem.lemmatize(word) for word in tweet\n",
    "             if word not in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "    print('--here goes nothing')\n",
    "    print(text)\n",
    "    print(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74fe009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['clean_text'] = test['text'].apply(lambda x: remove_URL(x))\n",
    "test['clean_text'] = test['text'].apply(lambda x: remove_html(x))\n",
    "test['clean_text'] = test['text'].apply(lambda x: remove_punct(x))\n",
    "test['clean_text'] = test['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a8042",
   "metadata": {},
   "source": [
    "## 3.4 Check processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf6180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>Malaysian PM confirms debris is from missing f...</td>\n",
       "      <td>malaysian pm confirms debris is from missing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>Officials: Alabama home quarantined over possi...</td>\n",
       "      <td>officials: alabama home quarantined over possi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>See the 16yr old PKK suicide bomber who detona...</td>\n",
       "      <td>see the 16yr old pkk suicide bomber who detona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>To conference attendees! The blue line from th...</td>\n",
       "      <td>to conference attendees! the blue line from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>The death toll in a #IS-suicide car bombing on...</td>\n",
       "      <td>the death toll in a #is-suicide car bombing on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>earthquake safety los angeles ûò safety faste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>storm in ri worse than last hurricane. my city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>green line derailment in chicago http://t.co/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>meg issues hazardous weather outlook (hwo) htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                                         clean_text\n",
       "3253  Malaysian PM confirms debris is from missing f...  malaysian pm confirms debris is from missing f...\n",
       "3254  Officials: Alabama home quarantined over possi...  officials: alabama home quarantined over possi...\n",
       "3255  See the 16yr old PKK suicide bomber who detona...  see the 16yr old pkk suicide bomber who detona...\n",
       "3256  To conference attendees! The blue line from th...  to conference attendees! the blue line from th...\n",
       "3257  The death toll in a #IS-suicide car bombing on...  the death toll in a #is-suicide car bombing on...\n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  earthquake safety los angeles ûò safety faste...\n",
       "3259  Storm in RI worse than last hurricane. My city...  storm in ri worse than last hurricane. my city...\n",
       "3260  Green Line derailment in Chicago http://t.co/U...  green line derailment in chicago http://t.co/u...\n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  meg issues hazardous weather outlook (hwo) htt..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[-10:-1][['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef5e68",
   "metadata": {},
   "source": [
    "# 4. Training with processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019d7c5",
   "metadata": {},
   "source": [
    "## 4.1 TFIDF  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400873ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(test['clean_text'], test['target'], test_size=0.1, random_state=20)\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text() process\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: 0.7584059775840598\n",
    "#     TfidfVectorizer(max_features = 1000), # F1 score: 0.7444514901712113\n",
    "#     TfidfVectorizer(max_features = 2000), # F1 score: 0.7542857142857142\n",
    "#     TfidfVectorizer(max_features = 3000), #  F1 score: 0.7531645569620253\n",
    "#     TfidfVectorizer(max_features = 10000), # F1 score: 0.7626800250469631 --> best\n",
    "#     TfidfVectorizer(max_features = 20000) # F1 score: 0.7584059775840598\n",
    "#     TfidfVectorizer(ngram_range =(1,2)), \n",
    "#     TfidfVectorizer(ngram_range =(1,3))\n",
    "# ]\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text() process + split tune\n",
    "# # split(test_size=0.2, stratify=train['target'], random_state=20)\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: 0.7348912167606769\n",
    "#     TfidfVectorizer(max_features = 1000), # F1 score: 0.7235099337748343\n",
    "#     TfidfVectorizer(max_features = 2000), # F1 score: 0.7358024691358025\n",
    "#     TfidfVectorizer(max_features = 3000), #  F1 score: 0.734860883797054\n",
    "#     TfidfVectorizer(max_features = 10000), # F1 score: 0.7408013082583811\n",
    "#     TfidfVectorizer(max_features = 20000) # F1 score: 0.7354838709677419\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text() process + split tune\n",
    "# # split(test_size=0.2, random_state=20)\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: F1 score: 0.7630331753554502   --> best\n",
    "#     TfidfVectorizer(max_features = 20000) # F1 score: 0.7630331753554502 --> best\n",
    "# ]\n",
    "\n",
    "# Apply Tfidf tranformation except message_text() process + split tune\n",
    "# split(test_size=0.1, random_state=20)\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: F1 score: 0.7682737169517885  \n",
    "#     TfidfVectorizer(max_features = 20000), # F1 score: 0.7701863354037266 --> best\n",
    "#     TfidfVectorizer(max_features = 30000)  # F1 score: 0.7682737169517885\n",
    "# ]\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text() process + split tune\n",
    "# # split(test_size=0.15, random_state=20)\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: 0.7643979057591623\n",
    "#     TfidfVectorizer(max_features = 10000), # F1 score: 0.7660020986358866\n",
    "#     TfidfVectorizer(max_features = 20000), # F1 score: 0.7635983263598327\n",
    "#     TfidfVectorizer(max_features = 30000)  # F1 score: 0.7643979057591623\n",
    "# ]\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text() process + split tune\n",
    "# # split(test_size=0.05, random_state=20)\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: F1 score: 0.7658227848101266\n",
    "# ]\n",
    "\n",
    "# # Apply Tfidf tranformation except message_text(), clean_text() process\n",
    "# vector = [\n",
    "#     TfidfVectorizer(), # F1 score: 0.7615433270082226\n",
    "#     TfidfVectorizer(max_features = 1000), # F1 score: 0.7399872854418309\n",
    "#     TfidfVectorizer(max_features = 2000), # F1 score: 0.7523629489603024\n",
    "#     TfidfVectorizer(max_features = 3000), #  F1 score: 0.7504714016341923\n",
    "#     TfidfVectorizer(max_features = 10000) # F1 score: 0.7574039067422811\n",
    "# ]\n",
    "\n",
    "# X_train_vector = vector.transform(X_train)\n",
    "# X_test_vector  = vector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256191a3",
   "metadata": {},
   "source": [
    "# 4.2 Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d51535c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre processed data for all method\n",
    "# MLA = [\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-3]),     # F1 score: 0.7113702623906706\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-2]),     # F1 score: 0.7109283196239718\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-1]),     # F1 score: 0.7368421052631579\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1]),        # F1 score: 0.741738066095471\n",
    "#     linear_model.RidgeClassifierCV(normalize=True),    # F1 score: 0.7209154481881755\n",
    "#     linear_model.RidgeClassifierCV(cv=5),              # F1 score: 0.7417380660954712\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1], cv=5),  # F1 score: 0.7417380660954712\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1], normalize=True),  #F1 score: 0.7209154481881755\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1], cv=10), # F1 score: 0.7417380660954712\n",
    "#     linear_model.RidgeClassifierCV(alphas=[10], cv=5) # F1 score: 0.707057256990679\n",
    "# ]\n",
    "\n",
    "## pre processed data except message_text()\n",
    "# MLA = [\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-3]),     # F1 score: 0.7272727272727273\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-2]),     # F1 score: 0.7326615293420273\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1e-1]),     # F1 score: 0.7485029940119761\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1])        # F1 score: 0.7584059775840598 -> best\n",
    "#     linear_model.RidgeClassifierCV(normalize=True),    # F1 score: 0.7189119170984455\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1], cv=5),  # F1 score: 0.7584059775840598\n",
    "#     linear_model.RidgeClassifierCV(alphas=[1], normalize=True),  # 0.7189119170984455\n",
    "#     linear_model.RidgeClassifierCV(alphas=[10], cv=5) # F1 score: 0.7264276228419655\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89d0981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       0\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test['clean_text']\n",
    "\n",
    "import joblib\n",
    "loaded_vector = joblib.load(open(\"./weights/vector002-2021-11-13-09-F1-077018.pkl\", \"rb\"))\n",
    "\n",
    "# import pickle\n",
    "# loaded_model = pickle.load(open(\"./weights/model002-2021-11-13-08-F1-077018.pkl\"))\n",
    "loaded_model = pickle.load(open(\"./weights/model002-2021-11-13-09-F1-077018.pkl\", \"rb\"))\n",
    "\n",
    "vec = loaded_vector\n",
    "X_test_vector  = vec.transform(X_test)\n",
    "\n",
    "# print(X_test_vector)\n",
    "\n",
    "# result = loaded_model.predict(X_test_vector)\n",
    "res = loaded_model.predict(X_test_vector.todense())\n",
    "\n",
    "df = pd.DataFrame(test['id'])\n",
    "df['target'] = res\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7971ff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2031\n",
       "1    1232\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('Disaster_tweet_submission.csv', index=False)\n",
    "\n",
    "check = pd.read_csv('Disaster_tweet_submission.csv')\n",
    "\n",
    "check.head()\n",
    "\n",
    "check.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
