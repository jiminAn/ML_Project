{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9db56b",
   "metadata": {},
   "source": [
    "# Disaster Tweet Classification with wordCount\n",
    "## NLP with Disaster Tweets\n",
    "------------------\n",
    "### GOAL\n",
    "- Predicting whether a given tweet is about a real disaster or not\n",
    "- if so, predict a `1`. if not, predict a `0`\n",
    "\n",
    "\n",
    "### Reference\n",
    "- [competition main page](https://www.kaggle.com/c/nlp-getting-started)\n",
    "- [example code](https://www.kaggle.com/datarohitingole/disaster-tweet-classification-ridgeclassifiercv)\n",
    "- [comparing the performance of different Machine Learning Algorithm](https://dibyendudeb.com/comparing-machine-learning-algorithms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fc9bf",
   "metadata": {},
   "source": [
    "# 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0811edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and preprocessing the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "\n",
    "# for training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import tree, linear_model, neighbors, naive_bayes, ensemble\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# for evaluating classification model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Comparing all machine learning algorithms\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f0b63",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "## Contents\n",
    "1. Dealing with Missing Values\n",
    "2. Convert Text to Vectors using Count Vectorizer\n",
    "\n",
    "## Data Description\n",
    "--------------\n",
    "### Files\n",
    "- `train.csv` : the training set\n",
    "- `test.csv` : the test set\n",
    "- `sample_submission.csv` : a sample submission file in the correct format\n",
    "\n",
    "### Columns\n",
    "- `id` : a unique identifier for each tweet\n",
    "- `text` : the text of the tweet\n",
    "- `location` : the location the tweet was sent from \n",
    "- `keyword` : a particular keyword from th tweet\n",
    "- `target` : in train.csv only, this denotes whether a tweet is about a real disaster(1) or not(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the .csv form data\n",
    "data_path = './data/'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "\n",
    "all_data = [train,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d35830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (7613, 5)\n",
      "test_shape; (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print('train_shape:', train.shape)\n",
    "print('test_shape;', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4ab3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25a1d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee02df",
   "metadata": {},
   "source": [
    "## 2-1. Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238d86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in all_data:\n",
    "    data.drop([\"location\", \"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d46b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepocessing with regrex\n",
    "\n",
    "def remove_URL(text): # remove url pattern in text\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "def remove_html(text): # remove html pattern in text\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return html.sub(r'', text)\n",
    "    #return re.sub(html, '', text)\n",
    "\n",
    "def remove_punct(text): # remove punctuation in text: (;, ', \", :, ., , etc..)\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6ec91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in all_data:\n",
    "  data['text'] = data['text'].apply(lambda x: remove_URL(x))\n",
    "  data['text'] = data['text'].apply(lambda x: remove_html(x))\n",
    "  data['text'] = data['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a2a0f",
   "metadata": {},
   "source": [
    "## 2-1. Convert Text to Vectors using Count Vectorizer\n",
    "\n",
    "### What is the Count Vectorizer?\n",
    "- convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "### How to Use\n",
    "```python\n",
    "# python example code\n",
    "corpus = [\"This is the first document\", \"This document is the second document\", \"And this is the thrid one\"]\n",
    "vectorize = CounterVectorize()\n",
    "X = vectorize.fit_transform(corpus)\n",
    "```\n",
    "- vectorizer.get_feature_names_out()\n",
    "> array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], ...)\n",
    "- X.toarray()\n",
    "> [[0 1 1 1 0 0 1 0 1]  \n",
    " [0 2 0 1 0 1 1 0 1]  \n",
    " [1 0 0 1 1 0 1 1 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd9a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=2000)\n",
    "\n",
    "X = count_vectorizer.fit_transform(train[\"text\"]).toarray()\n",
    "test = count_vectorizer.transform(test[\"text\"]).toarray()\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c32f3f",
   "metadata": {},
   "source": [
    "# 3. Model\n",
    "## Contents\n",
    "- split the data\n",
    "- train the model\n",
    "## Model Description\n",
    "--------------\n",
    "### Ensemble\n",
    "- Combine the predictions of several base estimators built with a given learning algorithm \n",
    "    - in order to improve generalizability / robustness over a single estimator.\n",
    "- Boosting of Ensemble types\n",
    "\n",
    "### Performance - f1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689075b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data <train : test = 8 : 2>\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6a51f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311     0\n",
      "4970    0\n",
      "527     0\n",
      "6362    0\n",
      "800     0\n",
      "       ..\n",
      "3728    1\n",
      "1657    0\n",
      "6367    1\n",
      "1670    0\n",
      "2839    1\n",
      "Name: target, Length: 1523, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375c53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "\n",
    "    XGBClassifier(),\n",
    "    CatBoostClassifier()  \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3f42a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ffbbbc37d8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMLA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclassifier_accuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "MLA_compare = pd.DataFrame()\n",
    "\n",
    "for classifier in MLA:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    classifier_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    MLA_name = classifier.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score*100\n",
    "\n",
    "    print(MLA_name, \"Done\")\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e11a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_compare = MLA_compare.sort_values(by=\"Accuracy Score\", ascending=False).reset_index(drop=True)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b2322",
   "metadata": {},
   "source": [
    "# Comapring all MLA\n",
    "- precision\n",
    "- recall\n",
    "- accuracy\n",
    "- f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac5e5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing all machine learning algorithms\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "\n",
    "row_index = 0\n",
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "for alg in MLA:\n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'MLA used'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 4)\n",
    "    MLA_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 4)\n",
    "    \n",
    "    \n",
    "    recall = recall_score(y_test, predicted)\n",
    "    precision = precision_score(y_test, predicted)\n",
    "    MLA_compare.loc[row_index, 'Precission'] = precision\n",
    "    MLA_compare.loc[row_index, 'Recall'] = recall\n",
    "    MLA_compare.loc[row_index, 'F1-score'] = round((2*precision*recall)/(precision+recall),4)\n",
    "    MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)\n",
    "\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1-score 기준 정렬\n",
    "MLA_compare.sort_values(by = ['F1-score'], ascending = False, inplace = True)    \n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "sns.barplot(x=\"MLA Name\", y=\"Accuracy Score\", data = MLA_compare)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Algorithm Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.RidgeClassifierCV(cv=15)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score : \", accuracy_score(y_test, y_pred), \"\\n\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98880c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_path + \"sample_submission.csv\")\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': sample_submission.id, 'target': test_pred})\n",
    "output.to_csv(data_path+'submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
