{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9db56b",
   "metadata": {},
   "source": [
    "# Compare word2vec and word counting\n",
    "## performing measurement\n",
    "### Disaster Tweet Classification with Disaster Tweets\n",
    "\n",
    "------------------\n",
    "### GOAL\n",
    "- comparing the performance of different word representation\n",
    "    - word2vec vs. word count\n",
    "- Predicting whether a given tweet is about a real disaster or not\n",
    "- if so, predict a `1`. if not, predict a `0`\n",
    "\n",
    "\n",
    "### Reference\n",
    "- [competition main page](https://www.kaggle.com/c/nlp-getting-started)\n",
    "- [word2vec code](https://www.kaggle.com/slatawa/simple-implementation-of-word2vec)\n",
    "- [word2vec-implementation-for-beginner](https://www.kaggle.com/manavkapadnis/nlp-word2vec-implementation-for-beginner)\n",
    "- [word count](https://www.kaggle.com/datarohitingole/disaster-tweet-classification-ridgeclassifiercv)\n",
    "- [comparing the performance of different Machine Learning Algorithm](https://dibyendudeb.com/comparing-machine-learning-algorithms/)\n",
    "- [Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT](https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fc9bf",
   "metadata": {},
   "source": [
    "# 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0811edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# for loading and preprocessing the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "\n",
    "# for training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import tree, linear_model, neighbors, naive_bayes, ensemble\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# for evaluating classification model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# for data cleaning\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "\n",
    "# for word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Comparing all machine learning algorithms\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f0b63",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "## Contents\n",
    "### 1. Clean the data\n",
    "- dealing with missing values\n",
    "- replace some commonly occuring shorthands\n",
    "- remove any characters other then alphabets\n",
    "- convert all dicitonary to lower case(for consistency)\n",
    "- lemmatize\n",
    "\n",
    "### 2-1. word tokenization and word2vec\n",
    "\n",
    "### 2-2. Convert text to vectors using Counter vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef4422",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Description\n",
    "--------------\n",
    "### Files\n",
    "- `train.csv` : the training set\n",
    "- `test.csv` : the test set\n",
    "- `sample_submission.csv` : a sample submission file in the correct format\n",
    "\n",
    "### Columns\n",
    "- `id` : a unique identifier for each tweet\n",
    "- `text` : the text of the tweet\n",
    "- `location` : the location the tweet was sent from \n",
    "- `keyword` : a particular keyword from th tweet\n",
    "- `target` : in train.csv only, this denotes whether a tweet is about a real disaster(1) or not(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data set\n",
    "data_path = './data/'\n",
    "train = pd.read_csv(data_path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879ad5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_shape:', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7081bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data <train : test = 8 : 2>\n",
    "train, test = train_test_split(train, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d35830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (6090, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1999</td>\n",
       "      <td>bush%20fires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ted Cruz fires back at Jeb &amp;amp; Bush: ÛÏWe l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>5751</td>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is the first year the Forest Service spen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>4428</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@lightseraphs pissed at you and could have the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>396</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>10678</td>\n",
       "      <td>wounds</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>@NicolaClements4 IÛªm not sure that covering ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         keyword   location  \\\n",
       "1386   1999    bush%20fires        NaN   \n",
       "4048   5751  forest%20fires        NaN   \n",
       "3086   4428     electrocute        NaN   \n",
       "272     396      apocalypse   ColoRADo   \n",
       "7462  10678          wounds  Tampa, FL   \n",
       "\n",
       "                                                   text  target  \n",
       "1386  Ted Cruz fires back at Jeb &amp; Bush: ÛÏWe l...       0  \n",
       "4048  This is the first year the Forest Service spen...       1  \n",
       "3086  @lightseraphs pissed at you and could have the...       0  \n",
       "272      I'm gonna fight Taylor as soon as I get there.       0  \n",
       "7462  @NicolaClements4 IÛªm not sure that covering ...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train shape:', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4ab3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (1523, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>454</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Wrigley Field</td>\n",
       "      <td>@KatieKatCubs you already know how this shit g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>7086</td>\n",
       "      <td>meltdown</td>\n",
       "      <td>Two Up Two Down</td>\n",
       "      <td>@LeMaireLee @danharmon People Near Meltdown Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>762</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>Score Team Goals Buying @</td>\n",
       "      <td>1-6 TIX Calgary Flames vs COL Avalanche Presea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>9094</td>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>If you ever think you running out of choices i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1160</td>\n",
       "      <td>blight</td>\n",
       "      <td>Laventillemoorings</td>\n",
       "      <td>If you dotish to blight your car go right ahea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         keyword                   location  \\\n",
       "311    454      armageddon              Wrigley Field   \n",
       "4970  7086        meltdown            Two Up Two Down   \n",
       "527    762       avalanche  Score Team Goals Buying @   \n",
       "6362  9094  suicide%20bomb                   Roadside   \n",
       "800   1160          blight        Laventillemoorings    \n",
       "\n",
       "                                                   text  target  \n",
       "311   @KatieKatCubs you already know how this shit g...       0  \n",
       "4970  @LeMaireLee @danharmon People Near Meltdown Co...       0  \n",
       "527   1-6 TIX Calgary Flames vs COL Avalanche Presea...       0  \n",
       "6362  If you ever think you running out of choices i...       0  \n",
       "800   If you dotish to blight your car go right ahea...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test shape:', test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee02df",
   "metadata": {},
   "source": [
    "## 1. Clean the data\n",
    "#### (1) Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f038183",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [train,test]\n",
    "for data in all_data:\n",
    "    data.drop([\"location\", \"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepocessing with regrex\n",
    "\n",
    "def remove_URL(text): # remove url pattern in text\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "def remove_html(text): # remove html pattern in text\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return html.sub(r'', text)\n",
    "    #return re.sub(html, '', text)\n",
    "\n",
    "def remove_punct(text): # remove punctuation in text: (;, ', \", :, ., , etc..)\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890d11a",
   "metadata": {},
   "source": [
    "#### (2) Replace some commonly occuring shorthands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00449129",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in all_data:\n",
    "  data['text'] = data['text'].apply(lambda x: remove_URL(x))\n",
    "  data['text'] = data['text'].apply(lambda x: remove_html(x))\n",
    "  data['text'] = data['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9e8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"i'll\", \"i will\", text)\n",
    "    text = re.sub(r\"she'll\", \"she will\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"here's\", \"here is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27c4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text'] = train['text'].apply(clean_text)\n",
    "test['clean_text'] = test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d40d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>bush%20fires</td>\n",
       "      <td>Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...</td>\n",
       "      <td>0</td>\n",
       "      <td>ted cruz fires back at jeb  bush ûïwe lose be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>This is the first year the Forest Service spen...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is the first year the forest service spen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>electrocute</td>\n",
       "      <td>lightseraphs pissed at you and could have thei...</td>\n",
       "      <td>0</td>\n",
       "      <td>lightseraphs pissed at you and could have thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Im gonna fight Taylor as soon as I get there</td>\n",
       "      <td>0</td>\n",
       "      <td>im gonna fight taylor as soon as i get there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>wounds</td>\n",
       "      <td>NicolaClements4 IÛªm not sure that covering m...</td>\n",
       "      <td>0</td>\n",
       "      <td>nicolaclements4 iûªm not sure that covering m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword                                               text  \\\n",
       "1386    bush%20fires  Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...   \n",
       "4048  forest%20fires  This is the first year the Forest Service spen...   \n",
       "3086     electrocute  lightseraphs pissed at you and could have thei...   \n",
       "272       apocalypse       Im gonna fight Taylor as soon as I get there   \n",
       "7462          wounds  NicolaClements4 IÛªm not sure that covering m...   \n",
       "\n",
       "      target                                         clean_text  \n",
       "1386       0  ted cruz fires back at jeb  bush ûïwe lose be...  \n",
       "4048       1  this is the first year the forest service spen...  \n",
       "3086       0  lightseraphs pissed at you and could have thei...  \n",
       "272        0       im gonna fight taylor as soon as i get there  \n",
       "7462       0  nicolaclements4 iûªm not sure that covering m...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d0957",
   "metadata": {},
   "source": [
    "#### (3) remove any characters other then alphabets\n",
    "#### (4) convert all dicitonary to lower case(for consistency)\n",
    "#### (5) lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8dc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def massage_text(text):\n",
    "    ## remove anything other then characters and put everything in lowercase\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', text) # (3)\n",
    "    tweet = tweet.lower() # (4) \n",
    "    tweet = tweet.split()\n",
    "\n",
    "    lem = WordNetLemmatizer() # (5)\n",
    "    tweet = [lem.lemmatize(word) for word in tweet\n",
    "             if word not in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "    print('--here goes nothing')\n",
    "    print(text)\n",
    "    print(tweet)\n",
    "\n",
    "train['clean_text'] = train['text'].apply(massage_text)\n",
    "test['clean_text'] = test['text'].apply(massage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b64f80e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...</td>\n",
       "      <td>ted cruz fire back jeb bush lose republican li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>This is the first year the Forest Service spen...</td>\n",
       "      <td>first year forest service spent half annual bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>lightseraphs pissed at you and could have thei...</td>\n",
       "      <td>lightseraphs pissed could pikachu electrocute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Im gonna fight Taylor as soon as I get there</td>\n",
       "      <td>im gonna fight taylor soon get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>NicolaClements4 IÛªm not sure that covering m...</td>\n",
       "      <td>nicolaclements sure covering head wound scab s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>kabwandi Breaking news Unconfirmed I just hear...</td>\n",
       "      <td>kabwandi breaking news unconfirmed heard loud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>The annihilation of Jeb Christie  Kasich is le...</td>\n",
       "      <td>annihilation jeb christie kasich le hour away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>Wtf this mom just drowned her child</td>\n",
       "      <td>wtf mom drowned child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>MayorofLondon pls reduce cyclist deaths with a...</td>\n",
       "      <td>mayoroflondon pls reduce cyclist death compuls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>DoctorDryadma mass murder here we come</td>\n",
       "      <td>doctordryadma mass murder come</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1386  Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...   \n",
       "4048  This is the first year the Forest Service spen...   \n",
       "3086  lightseraphs pissed at you and could have thei...   \n",
       "272        Im gonna fight Taylor as soon as I get there   \n",
       "7462  NicolaClements4 IÛªm not sure that covering m...   \n",
       "4778  kabwandi Breaking news Unconfirmed I just hear...   \n",
       "260   The annihilation of Jeb Christie  Kasich is le...   \n",
       "2921                Wtf this mom just drowned her child   \n",
       "2162  MayorofLondon pls reduce cyclist deaths with a...   \n",
       "4818             DoctorDryadma mass murder here we come   \n",
       "\n",
       "                                             clean_text  \n",
       "1386  ted cruz fire back jeb bush lose republican li...  \n",
       "4048  first year forest service spent half annual bu...  \n",
       "3086      lightseraphs pissed could pikachu electrocute  \n",
       "272                      im gonna fight taylor soon get  \n",
       "7462  nicolaclements sure covering head wound scab s...  \n",
       "4778  kabwandi breaking news unconfirmed heard loud ...  \n",
       "260   annihilation jeb christie kasich le hour away ...  \n",
       "2921                              wtf mom drowned child  \n",
       "2162  mayoroflondon pls reduce cyclist death compuls...  \n",
       "4818                     doctordryadma mass murder come  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0:10][['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e102222",
   "metadata": {},
   "source": [
    "## 2-1. Word Tokenization and word2vec\n",
    "- tokenize the clean text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab9734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens'] = train['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "test['tokens'] = test['clean_text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b48af0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>bush%20fires</td>\n",
       "      <td>Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...</td>\n",
       "      <td>0</td>\n",
       "      <td>ted cruz fire back jeb bush lose republican li...</td>\n",
       "      <td>[ted, cruz, fire, back, jeb, bush, lose, repub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>This is the first year the Forest Service spen...</td>\n",
       "      <td>1</td>\n",
       "      <td>first year forest service spent half annual bu...</td>\n",
       "      <td>[first, year, forest, service, spent, half, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>electrocute</td>\n",
       "      <td>lightseraphs pissed at you and could have thei...</td>\n",
       "      <td>0</td>\n",
       "      <td>lightseraphs pissed could pikachu electrocute</td>\n",
       "      <td>[lightseraphs, pissed, could, pikachu, electro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Im gonna fight Taylor as soon as I get there</td>\n",
       "      <td>0</td>\n",
       "      <td>im gonna fight taylor soon get</td>\n",
       "      <td>[im, gon, na, fight, taylor, soon, get]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>wounds</td>\n",
       "      <td>NicolaClements4 IÛªm not sure that covering m...</td>\n",
       "      <td>0</td>\n",
       "      <td>nicolaclements sure covering head wound scab s...</td>\n",
       "      <td>[nicolaclements, sure, covering, head, wound, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword                                               text  \\\n",
       "1386    bush%20fires  Ted Cruz fires back at Jeb  Bush ÛÏWe lose be...   \n",
       "4048  forest%20fires  This is the first year the Forest Service spen...   \n",
       "3086     electrocute  lightseraphs pissed at you and could have thei...   \n",
       "272       apocalypse       Im gonna fight Taylor as soon as I get there   \n",
       "7462          wounds  NicolaClements4 IÛªm not sure that covering m...   \n",
       "\n",
       "      target                                         clean_text  \\\n",
       "1386       0  ted cruz fire back jeb bush lose republican li...   \n",
       "4048       1  first year forest service spent half annual bu...   \n",
       "3086       0      lightseraphs pissed could pikachu electrocute   \n",
       "272        0                     im gonna fight taylor soon get   \n",
       "7462       0  nicolaclements sure covering head wound scab s...   \n",
       "\n",
       "                                                 tokens  \n",
       "1386  [ted, cruz, fire, back, jeb, bush, lose, repub...  \n",
       "4048  [first, year, forest, service, spent, half, an...  \n",
       "3086  [lightseraphs, pissed, could, pikachu, electro...  \n",
       "272             [im, gon, na, fight, taylor, soon, get]  \n",
       "7462  [nicolaclements, sure, covering, head, wound, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a57687",
   "metadata": {},
   "source": [
    "#### convert our data(words) into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd5f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, create a list corpus which we would be using to train word2vec mappings\n",
    "def fn_pre_process_data(doc):\n",
    "    for rec in doc:\n",
    "        yield gensim.utils.simple_preprocess(rec)\n",
    "\n",
    "corpus = list(fn_pre_process_data(train['clean_text']))\n",
    "corpus += list(fn_pre_process_data(test['clean_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "542afaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiated ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(581532, 681810)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inititate the embedding model, we will come back to the passed arguments later\n",
    "print('initiated ...')\n",
    "wv_model = Word2Vec(corpus,vector_size=150,window=3,min_count=2)\n",
    "#wv_model.build_vocab(corpus)\n",
    "wv_model.train(corpus,total_examples=len(corpus),epochs=10)\n",
    "#wv_model.save(data_path + 'word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba905f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the train and text tokens\n",
    "def get_word_embeddings(token_list,vector,k=150):\n",
    "    if len(token_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    else:\n",
    "\n",
    "        vectorized = [vector.wv[word] if word in vector.wv else np.random.rand(k) for word in token_list] \n",
    "    \n",
    "    sum = np.sum(vectorized,axis=0)\n",
    "    ## return the average\n",
    "    return sum/len(vectorized)       \n",
    "\n",
    "def get_embeddings(tokens,vector):\n",
    "        embeddings = tokens.apply(lambda x: get_word_embeddings(x, wv_model))\n",
    "        return list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd40bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = get_embeddings(train['tokens'],wv_model)\n",
    "test_embeddings = get_embeddings(test['tokens'],wv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e2ff06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model/'\n",
    "wv_model.save(model_path + 'word2vec_1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e1a70",
   "metadata": {},
   "source": [
    "## 2-2. Convert text to vectors using Counter vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ef025",
   "metadata": {},
   "source": [
    "### What is the Count Vectorizer?\n",
    "- convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "### How to Use\n",
    "```python\n",
    "# python example code\n",
    "corpus = [\"This is the first document\", \"This document is the second document\", \"And this is the thrid one\"]\n",
    "vectorize = CounterVectorize()\n",
    "X = vectorize.fit_transform(corpus)\n",
    "```\n",
    "- vectorizer.get_feature_names_out()\n",
    "> array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], ...)\n",
    "- X.toarray()\n",
    "> [[0 1 1 1 0 0 1 0 1]  \n",
    " [0 2 0 1 0 1 1 0 1]  \n",
    " [1 0 0 1 1 0 1 1 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec24298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=2000)\n",
    "\n",
    "X = count_vectorizer.fit_transform(train[\"clean_text\"]).toarray()\n",
    "test_tmp = count_vectorizer.transform(test[\"clean_text\"]).toarray()\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb4629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "X_test = test_tmp\n",
    "y_train = train['target']\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c32f3f",
   "metadata": {},
   "source": [
    "# 3. Model\n",
    "## Contents\n",
    "- train the model\n",
    "    - RidgeClassifierCV\n",
    "    - sgd classifier\n",
    "    - BernoulliNB \n",
    "    - RandomForest\n",
    "\n",
    "## Model Description\n",
    "--------------\n",
    "### Ensemble\n",
    "- Combine the predictions of several base estimators built with a given learning algorithm \n",
    "    - in order to improve generalizability / robustness over a single estimator.\n",
    "- Boosting of Ensemble types\n",
    "\n",
    "### Performance - f1-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7b75a",
   "metadata": {},
   "source": [
    "## 3-2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "375c53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b2322",
   "metadata": {},
   "source": [
    "# Comapring all MLA\n",
    "## word2vec\n",
    "- precision\n",
    "- recall\n",
    "- accuracy\n",
    "- f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fea1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.array(train_embeddings)\n",
    "test_embeddings = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc91899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing all machine learning algorithms\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "\n",
    "row_index = 0\n",
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "for alg in MLA:\n",
    "    predicted = alg.fit(train_embeddings, y_train).predict(test_embeddings)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'MLA used'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(train_embeddings,y_train), 4)\n",
    "    MLA_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(test_embeddings, y_test), 4)\n",
    "    \n",
    "    \n",
    "    recall = recall_score(test['target'], predicted)\n",
    "    precision = precision_score(test['target'], predicted)\n",
    "    MLA_compare.loc[row_index, 'Precission'] = precision\n",
    "    MLA_compare.loc[row_index, 'Recall'] = recall\n",
    "    MLA_compare.loc[row_index, 'F1-score'] = round((2*precision*recall)/(precision+recall),4)\n",
    "    MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)\n",
    "\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "593d7ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA used</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.682456</td>\n",
       "      <td>0.610675</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.703193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.533752</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>0.710443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.481947</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>0.683976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.521092</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.5821</td>\n",
       "      <td>0.611837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MLA used  Train Accuracy  Test Accuracy  Precission  \\\n",
       "2           SGDClassifier          0.7358         0.7183    0.682456   \n",
       "0  RandomForestClassifier          0.9890         0.7393    0.772727   \n",
       "1       RidgeClassifierCV          0.7236         0.7170    0.752451   \n",
       "3             BernoulliNB          0.5924         0.6041    0.521092   \n",
       "\n",
       "     Recall  F1-score       AUC  \n",
       "2  0.610675    0.6446  0.703193  \n",
       "0  0.533752    0.6314  0.710443  \n",
       "1  0.481947    0.5876  0.683976  \n",
       "3  0.659341    0.5821  0.611837  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1-score 기준 정렬\n",
    "MLA_compare.sort_values(by = ['F1-score'], ascending = False, inplace = True)    \n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa7902",
   "metadata": {},
   "source": [
    "# Comapring all MLA\n",
    "## wordCount\n",
    "- precision\n",
    "- recall\n",
    "- accuracy\n",
    "- f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81de4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing all machine learning algorithms\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "\n",
    "row_index = 0\n",
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "for alg in MLA:\n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'MLA used'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 4)\n",
    "    MLA_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 4)\n",
    "    \n",
    "    \n",
    "    recall = recall_score(y_test, predicted)\n",
    "    precision = precision_score(y_test, predicted)\n",
    "    MLA_compare.loc[row_index, 'Precission'] = precision\n",
    "    MLA_compare.loc[row_index, 'Recall'] = recall\n",
    "    MLA_compare.loc[row_index, 'F1-score'] = round((2*precision*recall)/(precision+recall),4)\n",
    "    MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)\n",
    "\n",
    "    row_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abea8126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA used</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.833002</td>\n",
       "      <td>0.657771</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.781481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.759729</td>\n",
       "      <td>0.704867</td>\n",
       "      <td>0.7313</td>\n",
       "      <td>0.772298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.777434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.684458</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.757579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MLA used  Train Accuracy  Test Accuracy  Precission  \\\n",
       "1       RidgeClassifierCV          0.8677         0.8017    0.833002   \n",
       "2           SGDClassifier          0.9118         0.7833    0.759729   \n",
       "3             BernoulliNB          0.8417         0.7978    0.827038   \n",
       "0  RandomForestClassifier          0.9800         0.7695    0.744027   \n",
       "\n",
       "     Recall  F1-score       AUC  \n",
       "1  0.657771    0.7351  0.781481  \n",
       "2  0.704867    0.7313  0.772298  \n",
       "3  0.653061    0.7298  0.777434  \n",
       "0  0.684458    0.7130  0.757579  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1-score 기준 정렬\n",
    "MLA_compare.sort_values(by = ['F1-score'], ascending = False, inplace = True)    \n",
    "MLA_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
